<html>
<HEAD>
<LINK REL=StyleSheet HREF="../style.css" TYPE="text/css">
<LINK REL=StyleSheet HREF="style-print.css" TYPE="text/css" MEDIA=print>
</HEAD>

<BODY>
<h1>Lookup Classifiers</h1>
<index name="classifiers+lookup classification">

<P>Lookup classifiers predict classes by looking into stored lists of cases. There are two kinds of such classifiers in Orange. The simpler and fastest <CODE><INDEX name="classes/ClassifierByLookupTable">ClassifierByLookupTable</CODE> use up to three discrete attributes and have a stored mapping from values of those attributes to class value. The more complex classifiers stores an <CODE>ExampleTable</CODE> and predicts the class by matching the example to examples in the table.</P>

<P>The natural habitat of these classifiers is feature construction: they usually reside in <CODE>getValueFrom</CODE> fields of constructed attributes to facilitate their automatic computation. For instance, the following script shows how to translate the Monk 1 dataset features into a more useful subset that will only include the attributes <CODE>a</CODE>, <CODE>b</CODE>, <CODE>e</CODE>, and attributes that will tell whether <CODE>a</CODE> and <CODE>b</CODE> are equal and whether <CODE>e</CODE> is 1 (don't bother the details, they follow later).</P>

<p class="header"><a href="ClassifierByLookupTable.py">part of ClassifierByLookupTable.py</a>
(uses <a href="monk1.tab">monk1.tab</a>)</p>
<XMP class=code>import orange

data = orange.ExampleTable("monk1")
a, b, e = data.domain["a"], data.domain["b"], data.domain["e"]

ab = orange.EnumVariable("a==b", values = ["no", "yes"])
ab.getValueFrom = orange.ClassifierByLookupTable(ab, a, b, \
  ["yes", "no", "no",   "no", "yes", "no",   "no", "no", "yes"])

e1 = orange.EnumVariable("e==1", values = ["no", "yes"])
e1.getValueFrom = orange.ClassifierByLookupTable(e1, e, \
  ["yes", "no", "no", "no", "?"])

data2 = data.select([a, b, ab, e, e1, data.domain.classVar])
</XMP>

<P>We can check the correctness of the script by printing out several random examples from <CODE>data2</CODE>.</p>

<XMP class=code>>>> for i in range(5):
...     print data2.randomexample()
['1', '1', 'yes', '4', 'no', '1']
['3', '3', 'yes', '2', 'no', '1']
['2', '1', 'no', '4', 'no', '0']
['2', '1', 'no', '1', 'yes', '1']
['1', '1', 'yes', '3', 'no', '1']
</XMP>

<P>The first <CODE>ClassifierByLookupTable</CODE> takes values of attributes <CODE>a</CODE> and <CODE>b</CODE> and computes the value of <CODE>ab</CODE> according to the rule given in the given table. The first three values correspond to <CODE>a</CODE>=1 and <CODE>b</CODE>=1, 2, 3; for the first combination, value of <CODE>ab</CODE> should be "yes", for the other two <CODE>a</CODE> and <CODE>b</CODE> are different. The next triplet correspond to <CODE>a</CODE>=2; here, the middle value is "yes"...</P>

<P>The second lookup is simpler: since it involves only a single attribute, the list is a simple one-to-one mapping from the four-valued <CODE>e</CODE> to the two-valued <CODE>e1</CODE>. The last value in the list is returned when <CODE>e</CODE> is unknown and tells that <CODE>e1</CODE> should be unknown then as well.</P>

<P>Note that you don't need <CODE>ClassifierByLookupTable</CODE> for this. The new attribute <CODE>e1</CODE> could be computed with a callback to Python, for instance:</P>

<XMP class=code>e2.getValueFrom = lambda ex, rw: orange.Value(e2, ex["e"]=="1")
</XMP>

<P>While functionally the same, using classifiers by lookup table is faster.</P>

<HR>

<H2>Classifiers by Lookup Table</H2>

<P>Although the above example used <CODE>ClassifierByLookupTable</CODE> as if it was a concrete class, <CODE>ClassifierByLookupTable</CODE> is actually abstract. Calling its constructor is a typical Orange trick: what you get, is never <CODE>ClassifierByLookupTable</CODE>, but either <CODE><INDEX name="classes/ClassifierByLookupTable1">ClassifierByLookupTable1</CODE>, <CODE><INDEX name="classes/ClassifierByLookupTable2">ClassifierByLookupTable2</CODE> and <CODE><INDEX name="classes/ClassifierByLookupTable3">ClassifierByLookupTable3</CODE>. As their names tell, the first classifies using a single attribute (so that's what we had for <CODE>e1</CODE>), the second uses a pair of attributes (and has been constructed for <CODE>ab</CODE> above), and the third uses three attributes. Class predictions for each combination of attribute values are stored in a (one dimensional) table.
To classify an example, the classifier computes an index of the element of the table that corresponds to the combination of attribute values.</P>

<P>These classifiers are built to be fast, not safe. If you, for instance, change the number of values for one of the attributes, the Orange will most probably crash. To protect you somewhat, many of these classes' attributes are read-only and can only be set when the object is constructed.</P>

<P class=section>Attributes</P>
<DL class=attributes>

<DT>variable1[, variable2[, variable3]]<SPAN class=normalfont>(read only)</SPAN></DT>
<DD>The attribute(s) that the classifier uses for classification. <CODE>ClassifierByLookupTable1</CODE> only has <CODE>variable1</CODE>, <CODE>ClassifierByLookupTable2</CODE> also has <CODE>variable2</CODE> and <CODE>ClassifierByLookupTable3</CODE> has all three.</DD>

<DT>variables <SPAN class=normalfont>(read only)</SPAN></DT>
<DD>The above variables, returned as a tuple.</DD>

<DT>noOfValues1, noOfValues2[, noOfValues3] <SPAN class=normalfont>(read only)</SPAN></DT>
<DD>The number of values for <CODE>variable1</CODE>, <CODE>variable2</CODE> and <CODE>variable3</CODE>. This is stored here to make the classifier faster. Those attributes are defined only for <CODE>ClassifierByLookupTable2</CODE> (the first two) and <CODE>ClassifierByLookupTable3</CODE> (all three).</DD>

<DT>lookupTable <SPAN class=normalfont>(read only)</SPAN></DT>
<DD>A list of values (<CODE>ValueList</CODE>), one for each possible combination of attributes. For <CODE>ClassifierByLookupTable1</CODE>, there is an additional element that is returned when the attribute's value is unknown. Values are ordered by values of attributes, with <CODE>variable1</CODE> being the most important. In case of two three valued attributes, the list order is therefore 1-1, 1-2, 1-3, 2-1, 2-2, 2-3, 3-1, 3-2, 3-3, where the first digit corresponds to <CODE>variable1</CODE> and the second to <CODE>variable2</CODE>.</P>

<P>The list is read-only in the sense that you cannot assign a new list to this field. You can, however, change its elements. Don't change its size, though.</DD>

<DT>distributions <SPAN class=normalfont>(read only)</SPAN></DT>
<DD>Similar to <CODE>lookupTable</CODE>, but is of type <CODE>DistributionList</CODE> and stores a distribution for each combination of values.</CODE>

<DT>dataDescription</DT>
<DD>An object of type <CODE>EFMDataDescription</CODE>, defined only for <CODE>ClassifierByLookupTable2</CODE> and <CODE>ClassifierByLookupTable3</CODE>. They use it to make predictions when one or more attribute values are unknown. <CODE>ClassifierByLookupTable1</CODE> doesn't need it since this case is covered by an additional element in <CODE>lookupTable</CODE> and <CODE>distributions</CODE>, as told above.</DD>
</DL>


<P class=section>Methods</P>
<dl class=attributes>
<DT>ClassifierByLookupTable(classVar, variable1[, variable2[, variable3]] [, lookupTable[, distributions]])</DT>
<DD>A general constructor that, based on the number of attribute descriptors, constructs one of the three classes discussed. If <CODE>lookupTable</CODE> and <CODE>distributions</CODE> are omitted, constructor also initializes <CODE>lookupTable</CODE> and <CODE>distributions</CODE> to two lists of the right sizes, but their elements are don't knows and empty distributions. If they are given, they must be of correct size.</DD>

<DT>ClassifierByLookupTable1(classVar, variable1 [, lookupTable, distributions])<BR>
ClassifierByLookupTable2(classVar, variable1, variable2, [, lookupTable[, distributions]])<BR>
ClassifierByLookupTable3(classVar, variable1, variable2, variable3, [, lookupTable[, distributions]])</dt>
<DD>Class-specific constructors that you can call instead of the general constructor. The number of attributes must match the constructor called.</DD>


<DT>getindex(example)</DT>
<DD>Returns an index into <CODE>lookupTable</CODE> or <CODE>distributions</CODE>. The formula depends upon the type of the classifier. If value<EM>i</EM> is <CODE>int(example[variable<EM>i</EM>])</CODE>, then the corresponding formulae are

<DL>
<DT><CODE>ClassifierByLookupTable1</CODE>:</DT>
<DD><CODE>index = value1</CODE>, or <CODE>len(lookupTable)-1</CODE> if value is unknown</DD>

<DT><CODE>ClassifierByLookupTable2</CODE>:</DT>
<DD><CODE>index = value1*noOfValues1 + value2</CODE>, or -1 if any value is unknown

<DT><CODE>ClassifierByLookupTable3</CODE>:</DT>
<DD><CODE>index = (value1*noOfValues1 + value2) * noOfValues2 + value3</CODE>, or -1 if any value is unknown</DD>
</DD>
</DL>
<P style="margin-top: 12pt">Let's see some indices for randomly chosen examples from the original table.</P>
<p class="header"><a href="ClassifierByLookupTable.py">part of ClassifierByLookupTable.py (continued from above)</a>
(uses <a href="monk1.tab">monk1.tab</a>)</p>
<XMP class=code>>>> for i in range(5):
...     ex = data.randomexample()
...     print "%s: ab %i, e1 %i " % (ex, \
...         ab.getValueFrom.getindex(ex), \
...         e1.getValueFrom.getindex(ex))
['1', '1', '2', '2', '4', '1', '1']: ab 0, e1 3
['3', '3', '1', '2', '2', '1', '1']: ab 8, e1 1
['2', '1', '2', '3', '4', '2', '0']: ab 3, e1 3
['2', '1', '1', '2', '1', '1', '1']: ab 3, e1 0
['1', '1', '1', '2', '3', '1', '1']: ab 0, e1 2
</XMP>
</DD>
</DL>


<H2>Classifier by ExampleTable</H2>

<P><CODE><INDEX name="classes/ClassifierByExampleTable">ClassifierByExampleTable</CODE> is the alternative to <CODE>ClassifierByLookupTable</CODE>. It is to be used when the classification is based on more than three attributes. Instead of having a lookup table, it stores an <CODE>ExampleTable</CODE>, which is optimized for a faster access.</P>

<P>This class is used in similar contexts as <CODE>ClassifierByLookupTable</CODE>. If you write, for instance, a constructive induction algorithm, it is recommendable that the values of the new attribute are computed either by one of classifiers by lookup table or by <CODE>ClassifierByExampleTable</CODE>, depending on the number of bound attributes.</P>

<P class=section>Attributes</P>
<DL class=attributes>
<DT>sortedExamples</DT>
<DD>An <CODE>ExampleTable</CODE> with sorted examples for lookup. Examples in the table can be merged; if there were multiple examples with the same attribute values (but possibly different classes), they are merged into a single example. Regardless of merging, class values in this table are distributed: their <CODE>svalue</CODE> contains a <CODE>Distribution</CODE>.</DD>

<DT>classifierForUnknown</DT>
<DD>This classifier is used to classify examples which were not found in the table. If <CODE>classifierForUnknown</CODE> is not set, don't know's are returned.</DD>

<DT>variables <SPAN class=normalfont>(read only)</SPAN></DT>
<DD>A tuple with attributes in the domain. This field is here so that <CODE>ClassifierByExampleTable</CODE> appears more similar to <CODE>ClassifierByLookupTable</CODE>. If a constructive induction algorithm returns the result in one of these classifiers, and you would like to check which attributes are used, you can use <CODE>variables</CODE> regardless of the class you actually got.</DD>
</DL>

<P>There are no specific methods for <CODE>ClassifierByExampleTable</CODE>. Since this is a classifier, it can be called. When the example to be classified includes unknown values, <CODE>classifierForUnknown</CODE> will be used if it is defined.</P>

<P>Although <CODE>ClassifierByExampleTable</CODE> is not really a classifier in the sense that you will use it to classify examples, but is rather a function for computation of intermediate values, it has an associated learner, <CODE>LookupLearner</CODE>. The learner's task is, basically, to construct an <CODE>ExampleTable</CODE> for <CODE>sortedExamples</CODE>. It sorts them, merges them and, of course, regards example weights in the process as well.</P>

<p class="header"><a href="ClassifierByExampleTable.py">part of ClassifierByExampleTable.py</a>
(uses <a href="monk1.tab">monk1.tab</a>)</p>
<XMP class=code>import orange

data = orange.ExampleTable("monk1")
a, b, e = data.domain["a"], data.domain["b"], data.domain["e"]

data_s = data.select([a, b, e, data.domain.classVar])
abe = orange.LookupLearner(data_s)
</XMP>

<P>In <CODE>data_s</CODE>, we have prepared a table in which examples are described only by <CODE>a</CODE>, <CODE>b</CODE>, <CODE>e</CODE> and the class. Learner constructs a <CODE>ClassifierByExampleTable</CODE> and stores examples from <CODE>data_s</CODE> into its <CODE>sortedExamples</CODE>. Examples are merged so that there are no duplicates.

<XMP class=code>>>> print len(data_s)
432
>>> print len(abe2.sortedExamples)
36
>>> for i in abe2.sortedExamples[:5]:
...     print i
['1', '1', '1', '1']
['1', '1', '2', '1']
['1', '1', '3', '1']
['1', '1', '4', '1']
['1', '2', '1', '1']
['1', '2', '2', '0']
['1', '2', '3', '0']
['1', '2', '4', '0']
['1', '3', '1', '1']
['1', '3', '2', '0']
</XMP>

<P>Well, there's a bit more here than meets the eye: each example's class value also stores the distribution of classes for all examples that were merged into it. In our case, the three attribute suffice to unambiguously determine the classes and, since example covered the entire space, all distributions have 12 examples in one of the class and none in the other.</P>

<XMP class=code>>>> for i in abe2.sortedExamples[:10]:
...     print i, i.getclass().svalue
['1', '1', '1', '1'] <0.000, 12.000>
['1', '1', '2', '1'] <0.000, 12.000>
['1', '1', '3', '1'] <0.000, 12.000>
['1', '1', '4', '1'] <0.000, 12.000>
['1', '2', '1', '1'] <0.000, 12.000>
['1', '2', '2', '0'] <12.000, 0.000>
['1', '2', '3', '0'] <12.000, 0.000>
['1', '2', '4', '0'] <12.000, 0.000>
['1', '3', '1', '1'] <0.000, 12.000>
['1', '3', '2', '0'] <12.000, 0.000>
</XMP>

<P><CODE>ClassifierByExampleTable</CODE> will usually used by <CODE>getValueFrom</CODE>. So, we would probably continue this by constructing a new attribute and put the classifier into its <CODE>getValueFrom</CODE>.</P>

<XMP class=code>>>> y2 = orange.EnumVariable("y2", values = ["0", "1"])
>>> y2.getValueFrom = abe
</XMP>

<P>There's something disturbing here. Although <CODE>abe</CODE> determines the value of <CODE>y2</CODE>, <CODE>abe.classVar</CODE> is still <CODE>y</CODE>. Orange doesn't bother (the whole example is artificial - you will seldom pack entire dataset in an <CODE>ClassifierByExampleTable</CODE>...), so shouldn't you. But still, for the sake of hygiene, you can conclude by

<XMP class=code>>>> abe.classVar = y2
</XMP>

<P>Whole story can be greatly simplified. <CODE>LookupLearner</CODE> can also be called differently than other learners. Besides examples, you can pass the new class attribute and the attributes that should be used for classification. This saves us from constructing <CODE>data_s</CODE> and reassigning the <CODE>classVar</CODE>. It doesn't set the <CODE>getValueFrom</CODE>, though.</P>

<p class="header"><a href="ClassifierByExampleTable.py">part of ClassifierByExampleTable.py</a>
(uses <a href="monk1.tab">monk1.tab</a>)</p>
<XMP class=code>import orange
data = orange.ExampleTable("monk1")
a, b, e = data.domain["a"], data.domain["b"], data.domain["e"]

y2 = orange.EnumVariable("y2", values = ["0", "1"])
abe2 = orange.LookupLearner(y2, [a, b, e], data)
</XMP>

<P>Let us, for the end, show another use of <CODE>LookupLearner</CODE>. With the alternative call arguments, it offers an easy way to observe attribute interactions. For this purpose, we shall omit <CODE>e</CODE>, and construct a <CODE>ClassifierByExampleTable</CODE> from <CODE>a</CODE> and <CODE>b</CODE> only.</P>

<p class="header"><a href="ClassifierByExampleTable.py">part of ClassifierByExampleTable.py</a>
(uses <a href="monk1.tab">monk1.tab</a>)</p>
<XMP class=code>y2 = orange.EnumVariable("y2", values = ["0", "1"])
abe2 = orange.LookupLearner(y2, [a, b], data)
for i in abe2.sortedExamples:
    print i, i.getclass().svalue
</XMP>

<P>The script's output show how the classes are distributed for different values of <CODE>a</CODE> and <CODE>b</CODE>.</P>

<XMP class=code>['1', '1', '1'] <0.000, 48.000>
['1', '2', '0'] <36.000, 12.000>
['1', '3', '0'] <36.000, 12.000>
['2', '1', '0'] <36.000, 12.000>
['2', '2', '1'] <0.000, 48.000>
['2', '3', '0'] <36.000, 12.000>
['3', '1', '0'] <36.000, 12.000>
['3', '2', '0'] <36.000, 12.000>
['3', '3', '1'] <0.000, 48.000>
</XMP>

<P>For instance, when <CODE>a</CODE> is '1' and <CODE>b</CODE> is '3', the majority class is '0', and the class distribution is 36:12 in favor of '0'.</P>

</BODY></HTML> 